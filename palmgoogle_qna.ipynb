{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36da37cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import GooglePalm\n",
    "\n",
    "api_key = 'AIzaSyCNNlyza-cqCsBEtz7kJMacbYzIjevOIL0' # get this free api key from https://makersuite.google.com/\n",
    "\n",
    "llm = GooglePalm(G=api_key, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eadb04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "poem = llm(\"Write a 4 line poem of my love for samosa\")\n",
    "print(poem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d848d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "essay = llm(\"write email requesting refund for electronic item\")\n",
    "print(essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a1e320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.llms import GooglePalm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dc8170",
   "metadata": {},
   "source": [
    "Now let's load data from  csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2453a921",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "\n",
    "loader = CSVLoader(file_path='online_education_qna_dataset.csv', source_column=\"prompt\")\n",
    "\n",
    "# Store the loaded data in the 'data' variable\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bf0637",
   "metadata": {},
   "source": [
    "Hugging Face Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7eec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "\n",
    "# Initialize instructor embeddings using the Hugging Face model\n",
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=\"hkunlp/instructor-large\")\n",
    "\n",
    "e = instructor_embeddings.embed_query(\"What is your refund policy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e275b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e9915f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "e[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5574a56c",
   "metadata": {},
   "source": [
    "Vector store using FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67944c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Create a FAISS instance for vector database from 'data'\n",
    "vectordb = FAISS.from_documents(documents=data,\n",
    "                                 embedding=instructor_embeddings)\n",
    "\n",
    "# Create a retriever for querying the vector database\n",
    "retriever = vectordb.as_retriever(score_threshold = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c91a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdocs = retriever.get_relevant_documents(\"how about job placement support?\")\n",
    "rdocs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47830cf8",
   "metadata": {},
   "source": [
    "Create RetrievalQA chain along with prompt template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085fa4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Given the following context and a question, generate an answer based on this context only.\n",
    "In the answer try to provide as much text as possible from \"response\" section in the source document context without making much changes.\n",
    "If the answer is not found in the context, kindly state \"I don't know.\" Don't try to make up an answer.\n",
    "\n",
    "CONTEXT: {context}\n",
    "\n",
    "QUESTION: {question}\"\"\"\n",
    "\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    ")\n",
    "chain_type_kwargs = {\"prompt\": PROMPT}\n",
    "\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "chain = RetrievalQA.from_chain_type(llm=llm,\n",
    "                            chain_type=\"stuff\",\n",
    "                            retriever=retriever,\n",
    "                            input_key=\"query\",\n",
    "                            return_source_documents=True,\n",
    "                            chain_type_kwargs=chain_type_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc15bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain('Do you provide job assistance and also do you provide job gurantee?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297b40a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
